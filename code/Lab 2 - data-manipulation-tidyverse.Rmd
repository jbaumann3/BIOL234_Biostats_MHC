---
title: 'Lab 2: Data manipulation and using Tidyverse'
author: "Justin Baumann"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: kable
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
---
# **LEARNING OBJECTIVES**
IN THIS LAB YOU WILL LEARN: </br>
1.) How to deal with dates and time in R (using lubridate) </br>
2.) How to subset, filter, and trim data</br>
3.) How to use the 'pipe' (%>%) in dplyr and Tidyverse </br>
4.) A first glimpse at a plot</br>

***

# **Additional Tutorials and Resources**
[basic intro to R tutorial](https://njsilbiger.github.io/GettingStarted/)

[A second intro to RStudio](https://ourcodingclub.github.io/tutorials/intro-to-r/)

[A really thorough video intro to R](https://rstudio.com/resources/webinars/a-gentle-introduction-to-tidy-statistics-in-r/)

[more R tutorials](https://njsilbiger.github.io/)

[A very user friendly resource](http://www.cookbook-r.com/)

[Want to TRY some stuff on your own? Use the RStudio.cloud primers](https://rstudio.cloud/learn/primers)

Need more help? Chat with instructors and also try googling it! Learning how to effectively search for help online is a great tool for learning and mastering R!

***

# **1.) Load all packages we need for this tutorial**
```{r warning=FALSE, message=FALSE}
#loading packages we need
library(tidyverse)
library(lubridate)

```


# **2.) Date and Time in R** {.tabset .tabset-pills}
R and really all programming languages have a difficult time with dates and times. Luckily, programmers have developed ways to get computer to understand dates and times as time series (so we can plot them on a graph axis and do analysis, for example). 

There are several common formats of date and time that we don't need to get into, but for many tools we use in the field we have a timestamp that includes day, month, year, and time (hours, minutes, and maybe seconds). When all of that info ends up in 1 column of a .csv it can be annoying and difficult to get R to understand what that column means. There are tons of ways to solve this problem but the easiest is definitely to just use some simple functions in the Lubridate package!

## **Read in some data to practice with**

```{r}
dat<-read.csv('https://raw.githubusercontent.com/jbaumann3/Intro-to-R-for-Ecology/main/final_bucket_mesocosm_apex_data.csv')
head(dat) #take a look at the data to see how it is formatted
str(dat) #what are the attributes of each column (NOTE the attirbutes of the date column -- it is a factor and we want it to be a date/time0)

```
***
## **Change date column (factor) to date/time format**
To do this we just need to recognize the order of or date/time. For example, we might have year, month, day, hours, minutes
OR day, month, year, hours, minutes in order from left to right. 

In this case we have: 07/01/2021 00:00:00 or month/day/year hours:minutes:seconds. We care about the order of these. 
So to simply, we have mdy_hms 
Lubridate has functions for all combinations of these formats. So, mdy_hms() is one. You may also have ymd_hm() or any other combo. You just enter your date info followed by an underscore and then your time info. Here's how you apply this!

```{r}
str(dat)

dat$date<-mdy_hms(dat$date) #converts our date column into a date/time object based on the format (order) of our date and time 

str(dat)# date is no longer a factor but is now a POSIXct object, which means it is in date/time format and can be used for plots and time series!


```
***
## **Why this matters**
Here we have two example graphs that show why dates are annoying and how using lubridate helps us!

**A graph using the raw data alone (not changing date to a date/time object)**
```{r echo=FALSE}
#read in data
dat<-read.csv('https://raw.githubusercontent.com/jbaumann3/Intro-to-R-for-Ecology/main/final_bucket_mesocosm_apex_data.csv')

#filter for only 1 probe (make data simpler for this example)
exdat<-dat %>%
  filter(probe_name=='B2_T2')

#graph date by value
ggplot(exdat, aes(x=date, y=value))+
  geom_line()+
  theme_classic()

```

**same graph after making date into a date/time object**
```{r echo=FALSE}
#read in data
dat<-read.csv('https://raw.githubusercontent.com/jbaumann3/Intro-to-R-for-Ecology/main/final_bucket_mesocosm_apex_data.csv')

#change date to date/time format
dat$date<-mdy_hms(dat$date) #converts our date column into a date/time object based on the format (order) of our date and time 

#filter for only 1 probe (make data simpler for this example)
exdat<-dat %>%
  filter(probe_name=='B2_T2')

ggplot(exdat, aes(x=date, y=value))+
  geom_line()+
  theme_classic()


```
***
#{-}

# **3.)Intro to Tidyverse (basic data manipulation)** {.tabset .tabset-pills}

## **Background </br>**
The package 'Tidyverse" in R is a really nice all encompassing package that actually contains many other packages you've likely used in the past (dplyr, plyr, and ggplot2 are all included). 
[List of packages within tidyverse](https://www.tidyverse.org/packages/).

Tidyverse is great because all of the packages like the same kinds of data. That means we can learn the tidyverse methods and apply them to nearly any analysis we want as long as we understand the format of our data. To make this all easier to understand, Tidyverse likes data formatted as columns and rows. Just like Excel would. This tends to be an easy way for us to think of data storage, especially if we are new to programming. In short, we can read data from excel (or a .csv) into R and use Tidyverse to organize, trim, graph, and analyze. Since Tidyverse is so versatile and relatively simple, it is what we are going to be learning in this course. If you have programming experience beyond this course and would like to use other methods that is ok with me. Just recognize that any skills, examples, graphs, or analysis pipelines I will show you in class are likely to be based on Tidyverse. 

This section contains some worked examples of Tidyverse best practices for data manipulation. If you just want a quick refresher, you can take a look at the **cheat sheet** below!

![](/home/jbaumann/BIOL234_Biostats_MHC/images/tidyverse_cheat_sheet.png)

***

## **Read in some data**
We can mess with a few data sets that are built into R or into R packages. 

A common one is mtcars, which is part of base R (attributes of a bunch of cars)
```{r}
head(mtcars)
```

Another fun one is CO2, which is also part of base R (CO2 uptake from different plants). Note: co2 (no caps) is also a dataset in R. It's just the CO2 concentration at Maona Loa observatory every year (as a list). 
```{r}
head(CO2)
```

You are welcome to use these to practice with or you can choose from any of the datasets in the 'datasets' or 'MASS' packages (you have to load the package to get the datasets).

You can also load in your own data or pick something from online, as we learned how to do last time.

For example, I am fond of the 'penguins' data from TidyTuesday. 
```{r}
penguins <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')
head(penguins)
```

***

## **Select or remove columns/rows**
Let's look at penguins
```{r}
head(penguins)
```

Now let's say we only really care about species and bill length. We can select those columns to keep and remove the rest of the columns because they are just clutter at this point. 
There are two ways we can do this: 
1.) Select the columns we want to keep 
2.) Select the columns we want to remove 

Here are two ways to do that:

**Base R example**
For those with some coding experience you may like this method as this syntax is common in other coding languages

**Step 1.)** Count the column numbers. Column 1 is the left most column. Remember we can use ncol() to count the total number of columns (useful when we have a huge number of columns)
```{r}
ncol(penguins) # we have 8 columns
```
Species is column 1 and bill length is column 3. Those are the only columns we want!

**Step 2.)** Select columns we want to keep using bracket syntax.
Here we wil use this basic syntax: df[rows, columns]
We can input the rows and/or columns we want inside our brackets. If we want more than 1 row or column we will need to use a 'c()' for concatenate (combine). 
To select just species and bill length we would do the following:
```{r}
head(penguins[,c(1,3)]) #Selecting NO specific rows and 2 columns (numbers 1 and 3)
```
**IMPORTANT** When we do this kind of manipulation it is super helpful to NAME the output. In the above example I didn't do that. If I don't name the output I cannot easily call it later. If I do name it, I can use it later and see it in my 'Environment' tab. So, I should do this: 
```{r}
pens<-penguins[,c(1,3)]
head(pens)
```

Now, here's how you do the same selection step by removing the columns you **DO NOT** want.
```{r}
pens2<-penguins[,-c(2,4:8)] #NOTE that ':' is just shorthand for all columns between 4 and 8. I could also use -c(2,4,5,6,7,8)
head(pens2)
```

***

**Tidyverse example (select())**

Perhaps that example above was a little confusing? This is why we like Tidyverse! We can do the same thing using the select() function in Tidyverse and it is easier!

I still want just species and bill length. Here's how I select them:
```{r}
head(select(penguins, species, bill_length_mm))
```
EASY. Don't forget to **name the output** for use later :)

Like this:
```{r}
shortpen<-select(penguins, species, bill_length_mm)
head(shortpen)
```
***

## **Subsetting and filtering data**

Sometimes we only want to look at data from a subset of the data frame </br>

For example, maybe we only want to examine data from chinstrap penguins in the penguins data. OR perhaps we only care about 4 cylinder cars in mtcars. We can filter out the data we don't want easily using Tidyverse (filter) or base R (subset)

**Tidyverse example - Using filter()**

Let's go ahead and filter the penguins data to only include chinstraphs and the mtcars data to only include 4 cylinder cars

The syntax for filter is: filter(df, column =><== number or factor)

```{r}
#filter penguins to only contain chinstrap
chins<-filter(penguins, species=='Chinstrap')
head(chins)
#confirm that we only have chinstraps
chins$species
```

Now for mtcars... 
```{r}
#filter mtcars to only contain 4 cylinder cars
cars4cyl<-filter(mtcars, cyl == "4")
head(cars4cyl)

#confirm it worked
str(cars4cyl) #str shows us the observations and variables in each column
cars4cyl$cyl #shows us only the observations in the cyl column!
```

**Base R example (subset)**
In this case, the subset() function that is in base R works almost exactly like the filter() function. You can essentially use them interchangably. 

```{r}
#subset mtcars to include only 4 cylinder cars
cars4cyl2.0<-subset(mtcars, cyl=='4')
cars4cyl2.0
```
***

## **Add new columns or change existing ones**

**Adding a new column**
Sometimes we may want to do some math on a column (or a series of columns). Maybe we want to calculate a ratio, volume, or area. Maybe we just want to scale a variable by taking the log or changing it from cm to mm. We can do all of this with the mutate() function in Tidyverse!

```{r}
#convert bill length to cm (and make a new column)
head(penguins)
mutpen<-(mutate(penguins, bill_length_cm=bill_length_mm/10))
head(mutpen)         
```

**Change existing column**
The code above makes a new column in which bill length in cm is added as a new column to the data frame. We could have also just done the math in the original column if we wanted. That would look like this: 
```{r}
head(penguins)
mutpen<-(mutate(penguins, bill_length_mm=bill_length_mm/10))
head(mutpen) 
```
**NOTE** This is misleading because now the values in bill_length_mm are in cm. Thus, it was better to just make a new column in this case. But you don't have to make a new column every time if you would prefer not to. Just be careful. 

**Column math in Base R**
Column manipulation is easy enough in base R as well. 
We can do the same thing we did above without Tidyverse like this: 

```{r}
penguins$bill_length_cm = penguins$bill_length_mm /10
head(penguins)
```

## **Pivot data (wide to long / long to wide)**

'Pivoting' data means changing the format of the data. Tidyverse and ggplot in particular tend to like data in 'long' format. **Long format** means few columns and many rows. **Wide format** is the opposite- many columns and fewer rows. 

Wide format is usually how the human brain organizes data. For example, a spreadsheet in which every species is in its own column is wide format. You might take this sheet to the field and record present/absence or count of each species at each site or something. This is great but it might be easier for us to calculate averages or do group based analysis in R if we have a column called 'species' in which every single species observation is a row. This leads to A LOT of repeated categorical variables (site, date, etc), which is fine. 

**Example of Long Format** 
The built in dataset 'fish_encounters' is a simple example of long format data. Penguins, iris, and others are also in long format but are more complex
```{r}
head(fish_encounters) # here we see 3 columns that track each fish (column 1) across MANY stations (column 2) 

```

**Converting from long to wide using pivot_wider (Tidyverse)**
Although we know that long format is preferred for working in Tidyverse and doing graphing and data analysis in R, we sometimes do want data to be in wide format. There are certain functions and operations that may require wide format. This is also the format that we are most likely to use in the field. So, let's convert fish_encounters back to what it likely was when the data were recorded in the field... 

```{r}
#penguins long to wide using pivot_wider

widefish<-fish_encounters %>%
  pivot_wider(names_from= station, values_from = seen)

head(widefish)

```
The resulting data frame above is a wide version of the orignal in which each station now has its own column. This is likely how we would record the data in the field! 

**Example of Wide Format Data**
Let's just use widefish for this since we just made it into wide format :)
```{r}
head(widefish)
```

**Converting from Wide to Long using pivot_longer (Tidyverse)**
```{r}
longfish<- widefish %>%
  pivot_longer(!fish, names_to = 'station', values_to = 'seen')

head(longfish)
```
And now we are back to our original data frame! The '!fish' means simply that we do not wish to pivot the fish column. It remains unchanged. A '!' before something in code usually means to exclude or remove. We've used names_to and values_to to give names to our new columns. pivot_longer will look for facotrs and put those in the names_to column and it will look for values (numeric) to pupt in the values_to column. 

**NOTES** There are MANY other ways to modify pivot_wider() and pivot_longer(). I encourage you to look in the help tab, the tidyR/ Tidyverse documentation online, and for other examples on google and stack overflow. 

***

# **4.) Combining functions with the pipe (%>%) syntax** {.tabset .tabset-pills}

## **What is a pipe?**
The pipe, denoted as '|' in most programming languages but as '%>%' in R, is used to link functions together. This is an oversimplification, but it works for our needs. 

A pipe (%>%) is useful when we want to do a sequence of actions to an original data frame. 
For example, maybe we want to select() some columns and then filter() the resulting selection before finally calculating an average (or something). We can do all of those steps individually or we can use pipes to do them all at once and create one output.

We can think of the pipe as the phrase "and then." I will show examples in the next section.

When not to use a pipe: 
1.) When you want to do manipulate multiple data frames at the same time
2.) When there are meanginful intermediate objects (aka we want an intermediate step to produce a named data frame)

***

## **How to use the pipe**
The pipe is coded as '%>%' and should have a single space on either side of it at all times. 

Let's do an example with penguins. Here we will select only species and bill length and then we will filter so that we only have chinstrap penguins. 

Remember that we think of pipe as the phrase **'and then'**

```{r}
head(penguins)

#pseudocode / logic: look at dataframe penguins AND THEN (%>%) select() species and bill length AND THEN (%>%) filter by chinstrap

pipepen<- penguins %>% #first step of the pipe is to call the orignal dataframe so we can modify it!
  select(species, bill_length_mm)%>% #selected our columns
  filter(species == 'Chinstrap') #filtered for chinstrap

head(pipepen) #it worked! We didn't have to mess with intermediate dataframes and we got exactly what we needed :)

```

Now we will learn how to use the pipe to do calculations that are more meaningful for us!

***

## **Grouping and summarize (average + error calculations)**
The pipe becomes especially useful when we are interesting in calculating averages. This is something you'll almost certainly be doing at some point for graphs and statistics! Pipes make this pretty easy. 

When thinking about scientific hypotheses and data analysis, we often consider how groups or populations vary (both within the group and between groups). As such, a simple statistical analysis that is common is called analysis of variance (ANOVA). We often also use linear models to assess differences between groups. We will get into statistical theory later, but this does mean that it is often meaningful to graph population and group level means (with error) for the sake of comparison. So let's learn how to calculate those!

There are three steps: 
1.) Manipulate the data as needed (correct format, select what you need, filter if necessary, etc)

2.) Group the data as needed (so R know how to calculate the averages)

3.) Do your calculatiuons!

Here's what that looks like in code form: 

Let's use mtcars and calculate the mean miles per gallon (mpg) of cars by cylinder.
```{r}
mpgpercyl<-mtcars%>%
  group_by(cyl)%>% #group = cylinder 
  summarize(mean=mean(mpg),error=sd(mpg)) # a simple summarize with just mean and standard deviation

head(mpgpercyl)

```

Now, maybe we want something more complex. Let's say we want to look only at 4 cylinder cars that have more than 100 horsepower. Then we want to see the min, max, and mean mpg in addition to some error. 
```{r}
mpgdf<-mtcars%>%
  filter(cyl=='4' , hp >100) %>% #filters mtcars to only include cars w/ 4 cylinders and hp greater than 100
  summarize(min = min(mpg), max = max(mpg), mean = mean(mpg), error=sd(mpg))

head(mpgdf)
```

Let's do one more using penguins. This time, I want to know how bill length various between species, islands, and sex. I also prefer to use standard error of the mean in my error bars over standard deviation. So I want to calculate that in my summarize function.
```{r}
head(penguins)

sumpens<- penguins %>%
  group_by(species, island, sex) %>%
  summarize(meanbill=mean(bill_length_mm), sd=sd(bill_length_mm), n=n(), se=sd/sqrt(n))%>%
  na.omit() #removes rows with NA values (a few rows would otherwise have NA in 'sex' due to sampling error in the field)

sumpens
```
As you can see, this is complex but with just a few lines we have all of the info we might need to make some pretty cool plots and visually inspect for differences. 

Some notes on the pieces of the summarize function I used up there:
meanbill is just a mean() calculation. sd is just a standard deviation calculation- sd(). n=n() calculate the sample size for each group. Standard error cannot be calculated with a built in function in R (without packages that we aren't using here) so I wrote the formula for it myself. 
Standard Error = standard deviation / squareroot(sample size) 
in other words: se=sd/sqrt(n)

PS: here's the payoff... we can use the dataframe we just made to build a really nice plot, like the one below. You will be learning ggplot next time! NOTE: this plot is about as complex as we'd ever expect you to get. So don't worry, we aren't starting with this kind of plot. 

```{r echo=FALSE}
library(ggsci)

pd=position_dodge(width=0.5)
ggplot(sumpens, aes(x=island, y=meanbill))+
  geom_point(data=sumpens, aes(x=island, y=meanbill, color=sex), size=3)+
  geom_errorbar(data=sumpens, aes(x=island, ymin=meanbill-se, ymax=meanbill+se),width=0.1)+
  theme_classic()+
  scale_color_aaas()+
  facet_wrap(~species)+
  theme(axis.text.x = element_text(angle = 90))

```

***

# **5.) Applying what we've learned - Data Wrangling Challenge**

Please create an RMarkdown document to complete this work and don't forget to push your work to github!

1.) Read in https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-05-04/water.csv 
check the format of the date column and change it using lubridate so it is correct 
</br>
2.) Pull a dataset from online ([tidytuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data)) or use a preloaded dataset in R 
</br>
2a.) Look at your data and generate a hypothesis about it - we will discuss hypothesis testing later, so don't stress about the details here. Just pick something you want to explore (like, green birds have larger beaks, or something)
2b.) Select columns to keep / remove </br>
2c.) Filter your data to include only some levels of a factor (for example, include only 1 of 3 species or something) </br>
2d.) Add a new column! You can use column math for this if you'd like (multiply stuff together, change the unit, etc) </br>
2e.) Try to pivot your data from long to wide (or wide to long) and then return it back to its original format! </br>
</br>
3.) Use a pipe to group and calculate means! </br>
4.) Knit your work into a html or pdf, save the output file and the .rmd file and submit them both on Moodle!






